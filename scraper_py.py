# -*- coding: utf-8 -*-
"""Scraper.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gx-nE0xmxOsVUBPn6sg_RBtdNJNpzSde
"""

import requests
import pandas as pd

# Define the URL and query parameters
url = "https://job-search-api1.p.rapidapi.com/v1/job-description-search"

# Modify query to search for entry-level cybersecurity jobs
querystring = {
    "q": "entry level cybersecurity",
    "page": "1",
    "country": "us",
    "city": "Seattle"
}

# Define the headers including the API key
headers = {
    "x-rapidapi-key": "92da8e5d2fmsh214ecbb135be802p15044bjsn5e71e5fd050f",
    "x-rapidapi-host": "job-search-api1.p.rapidapi.com"
}

# Make the API request
response = requests.get(url, headers=headers, params=querystring)

# Check if the response status code is OK (200)
if response.status_code == 200:
    # Parse the JSON response
    data = response.json()

    # Assuming the relevant job data is in a list under a key named "jobs" (modify if needed)
    jobs = data.get("jobs", [])  # Update key if the structure is different

    # Convert to DataFrame
    df = pd.DataFrame(jobs)

    # Save DataFrame to CSV
    df.to_csv('entry_level_cybersecurity_jobs.csv', index=False)
    print("Data saved to entry_level_cybersecurity_jobs.csv")
else:
    print(f"Failed to retrieve data: {response.status_code}")